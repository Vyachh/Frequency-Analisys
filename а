from collections import Counter

def pad_arrays(array1, array2):
    # Определяем максимальную длину для массивов
    max_length = max(len(array1), len(array2))
    
    # Добавляем недостающие элементы в каждый массив
    for i in range(max_length):
        # Получаем Counter для текущего индекса
        counter1 = array1[i] if i < len(array1) else Counter()
        counter2 = array2[i] if i < len(array2) else Counter()
        
        # Получаем все уникальные слова из Counter'ов
        all_words = set(counter1.keys()).union(set(counter2.keys()))
        
        # Добавляем отсутствующие слова с нулевой частотой
        for word in all_words:
            if word not in counter1:
                counter1[word] = 0
            if word not in counter2:
                counter2[word] = 0
        
        # Обновляем массивы
        array1[i] = counter1
        array2[i] = counter2
    
    return array1, array2

# Пример использования
array1 = [Counter({'apple': 3, 'banana': 2}), Counter({'orange': 1, 'grape': 4}), Counter({'pear': 5})]
array2 = [Counter({'apple': 2, 'banana': 1}), Counter({'orange': 2, 'pear': 3}), Counter({'grape': 4, 'kiwi': 2})]

array1, array2 = pad_arrays(array1, array2)
print(array1)
print(array2)

import mpld3
import numpy as np
import matplotlib.pyplot as plt
import file_paths as fp
from matplotlib import cm
from scipy.stats import spearmanr
from collections import Counter

label_fontsize = 7
max_textsize = 40

# def optimize_freqs_lists(list1, list2):
#     joint_list = list1 + list2

#     optimized_list1 = separate(joint_list.copy(), list1)
#     optimized_list2 = separate(joint_list.copy(), list2)

#     return optimized_list1, optimized_list2

# def separate(main_text, separated_text):
#     for word2 in separated_text:
#         for word1 in main_text: 
#             if(word1 == word2):
#                  main_text[word2] = 0
#     return main_text


def pad_arrays(array1, array2):
    max_length = max(len(array1), len(array2))
    
    for i in range(max_length):
        # Получаем Counter'ы для текущего индекса
        counter1 = array1[i] if i < len(array1) else Counter()
        counter2 = array2[i] if i < len(array2) else Counter()
        
        # Получаем все уникальные слова из Counter'ов
        all_words = set(counter1.keys()).union(set(counter2.keys()))
        
        # Добавляем отсутствующие слова с нулевой частотой
        for word in all_words:
            if word not in counter1:
                counter1[word] = 0
            if word not in counter2:
                counter2[word] = 0
        
        # Обновляем массивы
        if i < len(array1):
            array1[i] = counter1
        else:
            array1.append(counter1)
        
        if i < len(array2):
            array2[i] = counter2
        else:
            array2.append(counter2)
    
    return array1, array2

def calculate_corr_method(x, y, method):
    if method == 'pearson':
        return np.corrcoef(x, y)[0, 1]
    elif method == 'spearman':
        return spearmanr(x, y)[0]
    else:
        raise ValueError("Неподдерживаемый метод корреляции")

def plot_correlation(freqs_list, filenames, method, title):
    freqs_list, _ = pad_arrays(freqs_list[:1], freqs_list[1:])
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    for j, ax in enumerate(axes.flatten()):
        # Расширенные массивы
        array1, array2 = freqs_list[0], freqs_list[j + 1]
        
        # Приводим массивы к спискам слов и частот
        words1, freqs1 = zip(*array1.items())
        words2, freqs2 = zip(*array2.items())

        # Вычисляем коэффициенты корреляции
        corr_value = calculate_corr_method(freqs1, freqs2, method)

        # Названия осей
        xlabel = filenames[j + 1].replace(fp.default_path_files, '')[:max_textsize]
        ylabel = filenames[0].replace(fp.default_path_files, '')[:max_textsize]

        ax.set_xlabel(f'Частоты в {xlabel}...', fontsize=label_fontsize)
        ax.set_ylabel(f'Частоты в {ylabel}...', fontsize=label_fontsize)

        colors = cm.viridis(np.array(freqs1) / np.max(freqs1))
        ax.scatter(freqs1, freqs2, c=colors)
        ax.set_title(f'Корреляция {title.capitalize()}: {corr_value:.2f}')

    mpld3.save_html(fig, fp.default_path_figures + f"{title}.html")
    plt.tight_layout()
    plt.show()

def pearson(freqs_list=[], filenames=[]):
    plot_correlation(freqs_list, filenames, "pearson", 'Корреляция Пирсона')

def spearman(freqs_list=[], filenames=[]):
    plot_correlation(freqs_list, filenames, "spearman", 'Корреляция Спирмена')

def odds_ratios(freqs_list=[], filenames=[]):
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # Расширяем массивы до одинаковой длины
    freqs_list, _ = pad_arrays(freqs_list[:1], freqs_list[1:])
    
    for j, ax in enumerate(axes.flatten()):
        # Расширенные массивы
        array1, array2 = freqs_list[0], freqs_list[j + 1]

        # Приводим массивы к спискам слов и частот
        words1, freqs1 = zip(*array1.items())
        words2, freqs2 = zip(*array2.items())

        # Расчет корреляции Отношения шансов
        a = np.array(freqs1, dtype=np.float64)
        b = np.array([sum(freqs1) - a], dtype=np.float64)
        c = np.array(freqs2, dtype=np.float64)
        d = np.array([sum(freqs2) - c], dtype=np.float64)

        odds_ratios = (a * d) / (b * c)

        # Получение точек
        words = list(words1)
        values = list(odds_ratios)

        # Названия осей
        xlabel = filenames[j + 1].replace(fp.default_path_files, '')[:max_textsize]
        ylabel = filenames[0].replace(fp.default_path_files, '')[:max_textsize]

        ax.set_xlabel(f'Частоты в {xlabel}...', fontsize=label_fontsize, color='blue', verticalalignment='top')
        ax.set_ylabel(f'Частоты в {ylabel}...', fontsize=label_fontsize, color='blue')

        ax.scatter(values, words)
        ax.set_title('Отношение шансов')

    mpld3.save_html(fig, fp.default_path_figures + "odds_ratios.html")
    plt.tight_layout()
    plt.show()